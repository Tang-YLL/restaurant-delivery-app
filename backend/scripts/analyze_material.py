"""
Materialæ•°æ®åˆ†æè„šæœ¬(æ— éœ€æ•°æ®åº“)
å¿«é€Ÿåˆ†æMaterialæ–‡ä»¶å¤¹ä¸­çš„æ•°æ®
"""
import os
import json
import re
from pathlib import Path
from typing import Dict, List
from collections import Counter


# å•†å“åˆ†ç±»è§„åˆ™
CATEGORY_RULES = {
    "çƒ­èœ": {
        "keywords": ["ç‚’", "çˆ†", "ç†˜", "ç‚¸", "çƒ¹", "ç…", "è´´", "çƒ§", "ç„–", "ç‚–", "è’¸", "ç…®", "çƒ©", "ç‚", "è…Œ", "æ‹Œ", "çƒ¤", "å¤", "é…±", "æ‹”ä¸", "æŒ‚éœœ", "ç³–æ°´"],
        "exclude": ["å‡‰", "å†·"]
    },
    "å‡‰èœ": {
        "keywords": ["å‡‰æ‹Œ", "å‡‰èœ", "æ²™æ‹‰", "å†·ç›˜"],
        "include_any": True
    },
    "æ±¤ç±»": {
        "keywords": ["æ±¤", "ç¾¹", "ç²¥"],
        "exclude": ["ç‚’", "é¢", "é¥­"]
    },
    "ä¸»é£Ÿ": {
        "keywords": ["é¥­", "é¢", "ç²¥", "é¥ºå­", "é¦’å¤´", "åŒ…å­", "é¥¼", "ç²‰", "é¢åŒ…", "æ„é¢", "æŠ«è¨", "ç‚’é¥­", "ç‚’é¢", "çƒ©é¥­"],
        "include_any": True
    },
    "å°åƒ": {
        "keywords": ["å°åƒ", "é›¶é£Ÿ", "ç‚¹å¿ƒ", "ç”œå“", "è›‹ç³•", "é¥¼å¹²", "æ´¾"],
        "include_any": True
    },
    "é¥®å“": {
        "keywords": ["é¥®", "æ±", "èŒ¶", "å’–å•¡", "å¥¶æ˜”", "å¥¶", "è±†æµ†"],
        "exclude": ["èœ", "æ±¤"]
    },
    "æµ·é²œ": {
        "keywords": ["é±¼", "è™¾", "èŸ¹", "è´", "æµ·å‚", "é±¿é±¼", "ç« é±¼", "æ‰‡è´", "è›¤èœŠ", "é²é±¼", "é¾™è™¾"],
        "include_any": True
    },
    "è‚‰ç±»": {
        "keywords": ["çŒªè‚‰", "ç‰›è‚‰", "ç¾Šè‚‰", "é¸¡è‚‰", "é¸­è‚‰", "æ’éª¨", "è¹„", "äº”èŠ±è‚‰", "é‡Œè„Š", "ç‰›æ’"],
        "include_any": True
    },
    "ç´ é£Ÿ": {
        "keywords": ["ç´ ", "è”¬èœ", "èŒ", "è‡", "è±†è…", "è±†", "è…ç«¹"],
        "include_any": True
    },
    "ç«é”…": {
        "keywords": ["ç«é”…", "æ¶®", "é”…åº•"],
        "include_any": True
    },
    "çƒ§çƒ¤": {
        "keywords": ["çƒ§çƒ¤", "çƒ¤ä¸²", "çƒ¤è‚‰", "çƒ¤é±¼"],
        "include_any": True
    },
    "ç”œå“": {
        "keywords": ["ç”œ", "ç³–æ°´", "å¸ƒä¸", "æœå†»", "å†°æ·‡æ·‹"],
        "include_any": True
    },
    "çƒ˜ç„™": {
        "keywords": ["çƒ˜ç„™", "çƒ¤", "é¢åŒ…", "è›‹ç³•", "æ›²å¥‡", "é¥¼å¹²"],
        "include_any": True
    },
    "æ—¥æ–™": {
        "keywords": ["å¯¿å¸", "åˆºèº«", "å¤©å¦‡ç½—", "æ—¥å¼"],
        "include_any": True
    },
    "è¥¿é¤": {
        "keywords": ["æ„", "ç‰›æ’", "æ„é¢", "æŠ«è¨", "æ²™æ‹‰", "æ±‰å ¡"],
        "include_any": True
    }
}


def classify_product(title: str) -> str:
    """æ ¹æ®èœå“æ ‡é¢˜åˆ†ç±»"""
    title_clean = title.strip().lower()

    # æ£€æŸ¥æ¯ä¸ªåˆ†ç±»è§„åˆ™
    for category_name, rules in CATEGORY_RULES.items():
        keywords = rules.get("keywords", [])
        exclude = rules.get("exclude", [])
        include_any = rules.get("include_any", False)

        # æ£€æŸ¥æ’é™¤è¯
        if exclude:
            if any(exc in title_clean for exc in exclude):
                continue

        # æ£€æŸ¥å…³é”®è¯
        if include_any:
            if any(keyword in title_clean for keyword in keywords):
                return category_name
        else:
            if all(keyword in title_clean for keyword in keywords):
                return category_name

    return "çƒ­èœ"


def parse_views_favorites(views_str: str) -> tuple:
    """è§£ææµè§ˆé‡å’Œæ”¶è—é‡"""
    views = 0
    favorites = 0

    if views_str:
        match = re.search(r'(\d+)æµè§ˆ', views_str)
        if match:
            views = int(match.group(1))

        match = re.search(r'(\d+)æ”¶è—', views_str)
        if match:
            favorites = int(match.group(1))

    return views, favorites


def analyze_material(material_path: str):
    """åˆ†æMaterialæ–‡ä»¶å¤¹"""
    material_dir = Path(material_path)

    print("="*60)
    print("Materialæ•°æ®åˆ†ææŠ¥å‘Š")
    print("="*60)

    # ç»Ÿè®¡æ–‡ä»¶
    json_files = list(material_dir.glob("*.json"))
    png_files = list(material_dir.glob("*.png"))

    print(f"\nğŸ“ æ–‡ä»¶ç»Ÿè®¡:")
    print(f"  - JSONæ–‡ä»¶: {len(json_files)}")
    print(f"  - PNGå›¾ç‰‡: {len(png_files)}")

    # è§£ææ•°æ®
    products_data = []
    missing_images = []
    category_counter = Counter()

    print(f"\nğŸ“Š æ•°æ®è§£æä¸­...")

    for idx, json_file in enumerate(json_files, 1):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # æ£€æŸ¥å›¾ç‰‡
            png_file = json_file.with_suffix('.png')
            if not png_file.exists():
                missing_images.append({
                    "json_file": json_file.name,
                    "expected_png": png_file.name
                })

            # è§£ææ•°æ®
            title = data.get('title', '').strip()
            if not title:
                continue

            category = classify_product(title)
            views_str = data.get('views_and_favorites', '')
            views, favorites = parse_views_favorites(views_str)

            products_data.append({
                'title': title,
                'category': category,
                'views': views,
                'favorites': favorites,
                'has_image': png_file.exists()
            })

            category_counter[category] += 1

            if idx % 100 == 0:
                print(f"  è¿›åº¦: {idx}/{len(json_files)} ({idx*100//len(json_files)}%)")

        except Exception as e:
            print(f"  é”™è¯¯: {json_file.name}: {e}")

    # æ‰“å°ç»Ÿè®¡
    print(f"\nâœ“ æˆåŠŸè§£æ: {len(products_data)} æ¡æ•°æ®")
    print(f"âœ“ ç¼ºå¤±å›¾ç‰‡: {len(missing_images)} ä¸ª")

    # åˆ†ç±»ç»Ÿè®¡
    print(f"\nğŸ“ˆ å•†å“åˆ†ç±»åˆ†å¸ƒ (å…±{len(category_counter)}ä¸ªåˆ†ç±»):")
    for category, count in category_counter.most_common():
        percentage = count * 100 / len(products_data) if products_data else 0
        print(f"  {category:12s}: {count:4d} ({percentage:5.2f}%)")

    # æµè§ˆé‡ç»Ÿè®¡
    total_views = sum(p['views'] for p in products_data)
    total_favorites = sum(p['favorites'] for p in products_data)
    avg_views = total_views / len(products_data) if products_data else 0

    print(f"\nğŸ‘ï¸  æµè§ˆæ•°æ®:")
    print(f"  - æ€»æµè§ˆé‡: {total_views:,}")
    print(f"  - æ€»æ”¶è—é‡: {total_favorites:,}")
    print(f"  - å¹³å‡æµè§ˆé‡: {avg_views:.1f}")

    # å›¾ç‰‡å®Œæ•´æ€§
    image_integrity = (len(products_data) - len(missing_images)) / len(products_data) * 100 if products_data else 0
    print(f"\nğŸ–¼ï¸  å›¾ç‰‡å®Œæ•´æ€§: {image_integrity:.2f}%")

    # éªŒæ”¶æ ‡å‡†æ£€æŸ¥
    print(f"\n{'='*60}")
    print("éªŒæ”¶æ ‡å‡†æ£€æŸ¥")
    print(f"{'='*60}")

    checks = [
        ("è§£ææ‰€æœ‰JSONæ–‡ä»¶", len(products_data) >= 3000),
        ("åˆ›å»ºâ‰¥10ä¸ªå•†å“åˆ†ç±»", len(category_counter) >= 10),
        ("å¯¼å…¥â‰¥3000ä¸ªå•†å“SKU", len(products_data) >= 3000),
        ("å›¾ç‰‡å®Œæ•´æ€§â‰¥95%", image_integrity >= 95),
    ]

    all_passed = True
    for check_name, passed in checks:
        status = "âœ“ é€šè¿‡" if passed else "âœ— æœªé€šè¿‡"
        print(f"  {status} - {check_name}")
        if not passed:
            all_passed = False

    print(f"\n{'='*60}")
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰éªŒæ”¶æ ‡å‡†å‡å·²è¾¾æˆ!")
    else:
        print("âš ï¸  éƒ¨åˆ†éªŒæ”¶æ ‡å‡†æœªè¾¾æˆ,è¯·æ£€æŸ¥")
    print(f"{'='*60}\n")

    # å¯¼å‡ºåˆ†ææŠ¥å‘Š
    report = {
        "æ€»å•†å“æ•°": len(products_data),
        "åˆ†ç±»æ•°": len(category_counter),
        "åˆ†ç±»åˆ†å¸ƒ": dict(category_counter),
        "å›¾ç‰‡å®Œæ•´æ€§": f"{image_integrity:.2f}%",
        "ç¼ºå¤±å›¾ç‰‡æ•°": len(missing_images),
        "æ€»æµè§ˆé‡": total_views,
        "æ€»æ”¶è—é‡": total_favorites
    }

    report_path = Path("/Volumes/545S/general final/backend/analysis_report.json")
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“„ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_path}")

    return report, category_counter


if __name__ == "__main__":
    material_path = "/Volumes/545S/general final/Material/material"
    analyze_material(material_path)
